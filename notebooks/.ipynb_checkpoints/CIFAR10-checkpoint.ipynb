{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Learning on CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from pathlib import Path\n",
    "from context import LocalLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "test_data = LocalLearning.LpUnitCIFAR10(\n",
    "    root=\"../data/CIFAR10\",\n",
    "    train=False, \n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=1000,\n",
    "    num_workers=4,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating covariance spectrum: 100%|████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  7.97batch/s]\n"
     ]
    }
   ],
   "source": [
    "trained_weights_path = Path(\"../data/models/L2UnitCIFAR10_LL/cifar.pth\")\n",
    "cpu = torch.device('cpu')\n",
    "\n",
    "with torch.no_grad():\n",
    "    trained_state = torch.load(trained_weights_path)\n",
    "    model_ps = trained_state[\"model_parameters\"]\n",
    "    model = LocalLearning.FKHL3(model_ps)\n",
    "    model.eval()\n",
    "    model.load_state_dict(trained_state[\"model_state_dict\"])\n",
    "    model.to(device)\n",
    "    l_n_trained = LocalLearning.cov_spectrum(test_dataloader, model, device)\n",
    "    l_n_trained = l_n_trained.to(cpu).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (1999,) and (2000,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39muse([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseaborn-paper\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./PRLSingleCol.mplstyle\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      8\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots()\n\u001b[0;32m----> 9\u001b[0m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloglog\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43ml_n_trained\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml_n_trained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCIFAR10\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#ax.loglog(l_n_trained[0]*LocalLearning.stringer_spectrum(x), label=r\"$1 / n$\")\u001b[39;00m\n\u001b[1;32m     11\u001b[0m ax\u001b[38;5;241m.\u001b[39mlegend()\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/matplotlib/axes/_axes.py:1770\u001b[0m, in \u001b[0;36mAxes.loglog\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1766\u001b[0m dy \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1767\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbase\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnonpositive\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1768\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbasey\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubsy\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnonposy\u001b[39m\u001b[38;5;124m'\u001b[39m]}\n\u001b[1;32m   1769\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_yscale(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdy)\n\u001b[0;32m-> 1770\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1771\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdy\u001b[49m\u001b[43m}\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/matplotlib/axes/_axes.py:1632\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1392\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1629\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1630\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1631\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1632\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1633\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1634\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/matplotlib/axes/_base.py:312\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    311\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 312\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/matplotlib/axes/_base.py:498\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 498\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    499\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    502\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (1999,) and (2000,)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABCcAAAO3CAYAAAAQ9C5pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAC4jAAAuIwF4pT92AAA+QElEQVR4nO3deZR9Z13n+8+XhATDLyGAjCIQIgHyY0ogXLr1Aq2wQFtFaBGbVgbbAWTqqy3YrQ04dDsrgg2KjcLFAa64EIdmCOIMNpAwJYwBAohCkCkJIQHC9/5RFfwlqTpD1dnnqarf67VWrayc5zn7eSoJh5139tm7ujsAAAAAo1xn9AYAAACAo5s4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRNMojbcsaq+u6qeVVWvr6rPVVVv8fPo0fsFAABgnGNHb4CDoapuk+SsI37ukeSkoZsCAABgXxAn2LWq+vkkPzJ6HwAAAOxPvtbBKhw3egMAAADsX+IEAAAAMJSvdTC1zyd5e5I3JjmU5LvGbgcAAIC9Rpxgla5M8s5shIg3bf7xrd39+STZfCqHOAEAAMDViBOswkuSvDTJud192ejNAAAAsL+IE+xad79+9B52oqqul+TUI156X3dfPmo/AAAARytxgqPZqUnOO+LP75zk/EF7AQAAOGqJE7DpvPPOO2/+LAAAgNToDRw0HiUKAAAADCVOAAAAAEP5Wsc+U1XHJzktya2SnJjkhCSXJbkkyT8kefdVj+4EAACA/UCc2Aeq6t5Jvi3JNyY5nOSYGdOvrKrzk7wiyR91999Pv0MAAADYuQMVJ6qqsvEEhrOS3HPzj2ckOTTjbR/s7ttOv7vlVdXDkzwlyZlLvO2YJHfd/HlqVZ2b5Oe7+yUTbBEAAAB2bV/Hiaq6df4lQtxz8+fkkXtahaq6Y5JfT3LfFRzuzCQvrqrHJXlsd79rBccEAACAldk3caKqbpaNCHHkVRE3GbqpCVTVQ5O8MLOv9tiJ+yZ5Y1U9srtftuJjAwAAwI7tmziR5FVJ7jZ6E1OqqscneXame2buoSR/WFVP6O7nTLQGAAAALMWjRPeIqnpUpg0TX14qya9V1SMnXgcAAAAWIk7sAVV1VpLfzGJh4nVJnpCNe0ncKMl1N/94zyRPSrLI0zkqyW9urgsAAABD7aevdRxIVXVSkpdkIzLM8t4kj+vuP99i7FNJztn8eXZVPSDJc7Px5JLtHJfkJVV19+6+ePmdAwAAwGoc5CsnOhv/Qv/Xozcyx08mOWXOnNckOWubMHEt3X12Nq6keO2cqackecYixwQAAICpHKQ4cWGSP0jy1CTfkOSG3X1akqeP3NQsVXV6ksfPmfb6JA/u7s8sc+zu/nSSb03yhjlTn1hVd1rm2AAAALBK+/VrHR9J8sYkb7rqp7s/MXZLO/L0zP578MkkD+/uy3Zy8O7+bFV9R5K3JDl5m2nHJnlakn+/kzUAAABgt/ZTnHh2ko8leWN3f2z0Znarqm6X5N/Nmfbj3f3h3azT3R+sqqcn+dUZ0x5WVf+1uz+wm7UAAABgJ/bN1zq6+/nd/acHIUxsenySY2aMvzfJ81a01nOSvH/G+DFJfnBFawEAAMBS9k2cOEiq6jqZ/zWKX+nuK1exXnd/MbOvnEiSR2zuCwAAANbKv4yO8fVJbjFj/PIkv7PiNV+Y5IoZ47dMcr8VrwkAAABziRNjfMuc8T/r7ktWueDm0z5eOWfavH0BAADAyokTY9x/zvifTbTuvOM+YKJ1AQAAYFvixJpV1S2SnD5n2msmWv7sOeOHq+rmE60NAAAAWxIn1u9ec8Y/vNvHh26nuy9M8o9zpp01xdoAAACwHXFi/c6YM37uxOufM2d83v4AAABgpcSJ9bv7nPG3Tbz+W+eMixMAAACslTixfqfNGX/vxOu/b8747SdeHwAAAK5GnFi/284Zv2Di9ecd/5SJ1wcAAICrESfWaPNJGF8xZ9pHJt7GvOOfUFU3nXgPAAAA8GXHjt7AUeaWC8z52MR7+OgCc26Z5KJlDlpV353kNnOmbXc/i2+pqlvNee8Hu/tFy+wJAACA/UGcWK8bzxm/uLuvmHID3f25qro0yaEZ0+btcyv/Mcl9d7arPHTzZ5a/SiJOAAAAHEC+1rFeN5ozfvFadjF/nXn7BAAAgJURJ9brhnPGxQkAAACOOr7WsV7XmzN+2Vp2kXx2zvi8fe45mzfxvMmSbzt1ir0AAACwHHFivY6bM/7Ftexi/jrz9nkt3X2/nW1lZX4wydMH7wEAAIAd8LWO9TqwcQIAAAB2SpxYr3l/va9cyy7mr3PMWnYBAAAA8bWOdZt3xcK6/n7MW+cLa9nFaj0nyR8s+Z5Tk7x8gr0AAACwBHFivT4/Z3xdfz+uO2d83j73nO6+KMlFy7ynqibaDQAAAMvwtY71mndFwrru9XDg4gQAAAD7lzixXpfOGT9xLbtITpozPm+fAAAAsDLixHp9cs74uuLEvHXm7RMAAABWRpxYr0/MGT95HZtIcoM54/P2CQAAACsjTqzXP88ZP76qTp5yA1V148y/t4U4AQAAwNqIE+v1oQXm3GziPSxy/EX2CQAAACshTqxRd1+a+VdP3Gbibcw7/kXd/dmJ9wAAAABfJk6s3wfmjN9+4vXnHX/e/gAAAGClxIn1O3/O+B0mXv+0OePz9gcAAAArJU6s35vnjJ8x8fpnzhmftz8AAABYKXFi/c6dM373qjpmioWr6tgkd5szTZwAAABgrcSJ9XtTkstnjB9Kco+J1r5XkhNmjF+e5JyJ1gYAAIAtiRNr1t2XJ/nbOdMeMNHy958z/jeb+wMAAIC1ESfGOHvO+EMnWvfb54y/eqJ1AQAAYFvixBgvnTN+ZlWt9KkdVXU4yV3mTPvDVa4JAAAAixAnBuju9yd5/ZxpT1zxsk+aM/533f2BFa8JAAAAc4kT4/z2nPHHVNUtVrFQVd0qySPnTHvBKtYCAACAZYkT47woyUUzxk9I8rMrWuvnklxvxvjHNvcDAAAAaydODLL5VIxfnTPtkVX1kN2sU1UPS/KIOdOe2d1X7GYdAAAA2ClxYqxnJvnQnDkvrKp77eTgVXXvJL81Z9qHMj+SAAAAwGTEiYG6+7IkPzxn2olJXl1V37LMsavqwUleleTQnKk/1N2fW+bYAAAAsErHjt7AMqrqPklOW/Jt8x7JeaiqvncH2/mr7n7vDt53Nd390qr6vcz+6sUNkry8qn4/yU9197u2m1hVpyd5WpKHL7D873a3x4cCAAAwVHX36D0srKpekORRo/ex6THd/YJVHKiqDiV5Y5I7LviWNyd5XZIPJLk0G1dXnJLka5PcbcFjvCvJWd196XK7PTiq6nCS86768/POOy+HDx8euCMAAGCfqNEbOGj21ZUTB1V3X1pVD0zyN0luvcBbztj82akPJXng0RwmAAAA2Dvcc2KP6O4PJfmGJO+beKkLknz95noAAAAwnDixh3T3BUnOysaNLKfwyiT36u6pAwgAAAAsTJzYY7r7U939oCSPTnLRig57UZJHdfc3dvenVnRMAAAAWAn3nNijuvuFVfXSbNwA9AlJ7rSDw7wzya8lecHmY0uPSlV1/jZDx691IwAAAGxpXz2t42hWVacleVCSM5McTvJV2XhKxwlJLktySZJ/SPKOJOcmecUqHnV6EMyJE6de9See1gEAACzI0zpWzJUT+0R3vyfJe0bvYz/q7i2LwzUfJQoAAMAY7jkBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADHXs6A3A1Krq/G2Gjl/rRgAAANiSKycAAACAoVw5wYHX3Ye3er2qDic5b83bAQAA4BpcOQEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMdezoDcDUqur8bYaOX+tGAAAA2JIrJwAAAIChXDnBgdfdh7d6vaoOJzlvzdsBAADgGlw5AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMNSxozcAU6uq87cZOn6tGwEAAGBLrpwAAAAAhnLlBAdedx/e6vWqOpzkvDVvBwAAgGtw5QQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQx47eAEytqs7fZuj4tW4EAACALblyAgAAABjKlRMceN19eKvXq+pwkvPWvB0AAACuwZUTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQx07egMwtao6f5uh49e6EQAAALbkygkAAABgKFdOcOB19+GtXq+qw0nOW/N2AAAAuAZXTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAwlTgAAAABDiRMAAADAUOIEAAAAMJQ4AQAAAAx17OgNwNSq6vxtho5f60YAAADYkisnAAAAgKFcOcGB192Ht3q9qg4nOW/N2wEAAOAaXDkBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQ4gQAAAAwlDgBAAAADCVOAAAAAEOJEwAAAMBQx47eAEytqs7fZuj4tW4EAACALblyAgAAABjKlRMceN19eKvXq+pwkvPWvB0AAACuwZUTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMJU4AAAAAQ4kTAAAAwFDiBAAAADCUOAEAAAAMdezoDXBwVVUlOT3J4SQ3S3L9JJ9L8vEk70zy9u7+4rgdAgAAsBeIE6xcVZ2e5ElJHpLkpjOmfqaq/iTJs7v7DWvZHAAAAHuOr3WwMlV1UlU9N8nbk/xAZoeJJLlBku9K8n+q6iVVdbOp9wgAAMDeI06wElV1uyR/n+Sx2dk/V9+R5E1VdcZKNwYAAMCeJ06wa1X11Un+IsmddnmoWyV5TVXdZfe7AgAAYL8QJ9iVqjouycuS3HqL4U7ykiTflI2veFw3yY2TfEOS/5XkC1u850ZJXl5VN5hkwwAAAOw54gS79fQk99ji9Y8n+fru/s7ufkV3f7y7v9jdn+zu13b3922+7/1bvPeUJM+acM8AAADsIeIEO7Z5n4kf3mLos0ke0N1/Oev93f32JPdL8tEthr+7qu692z0CAACw94kT7MaPJjl+i9f/c3e/dZEDdPeHkzxmi6FK8t92sTcAAAD2CXGCHamqGyV55BZD70jyvGWO1d2vTPKqLYa+qarusIPtAQAAsI+IE+zUw7L1VRO/3N1f2sHxfnGb179rB8cCAABgHxEn2Klv3+K1K5L8wQ6P99ok/7jF6w/b4fEAAADYJ8QJllZV10vydVsM/XV3X7yTY25ebfGKLYbuUFVfvZNjAgAAsD8cO3oDLKaqjk9yWpJbJTkxyQlJLktySZJ/SPLu7v78mrZzVpLrbfH6X+7yuH+R5D9u8fp9k/zOLo8NAADAHiVO7GGbj9L8tiTfmORwkmNmTL+yqs7PxtUHf9Tdfz/h1s7c5vVzdnncN23z+hkRJwAAAA6sAxEnqqqSnJqN/6J/z80/npHk0Iy3fbC7bzv97pZXVQ9P8pRsHwG2ckySu27+PLWqzk3y8939kgm2eNdtXj9/l8e9IMnnkxx3jdfvssvjAgAAsIftyzhRVbfOv0SIe27+nDxyT6tQVXdM8uvZ+BrDbp2Z5MVV9bgkj+3ud63gmFe53RavfS7JR3Zz0O6+sqouzMbXV+atBwAAwAGx5+NEVd0sGxHiyKsibjJ0UxOoqocmeWFmX+2xE/dN8saqemR3v2xFx7zNFq/9U3f3Co79j7l2nLh1VV1nh48oBQAAYI/b83EiyauS3G30JqZUVY9P8uwkNdESh5L8YVU9obufs4Lj3XSL1z66guNud5zrZuPKmE+uaA0AAAD2EI8SHayqHpVpw8SXl0rya1X1yF0dpOq4JNffYugzuznuAse50YqODwAAwB4jTgxUVWcl+c0sFiZel+QJ2biXxI2ycTXBjbLxVZcnJVnk6RyV5Dc3192pE7d5/dJdHPNIlyy5LgAAAPvcfvhax4FUVScleUk2IsMs703yuO7+8y3GPpWNx3eek+TZVfWAJM/NxpNLtnNckpdU1d27++Lld36tJ2lc5fM7ONZWvrDN68ev6PgAAADsMQfxyonOxr/Q//Xojczxk0lOmTPnNUnO2iZMXEt3n52NKyleO2fqKUmescgxt7BdTPniDo93TdvFiXkRBwAAgH3qIMSJC5P8QZKnJvmGJDfs7tOSPH3kpmapqtOTPH7OtNcneXB3L3Uvh+7+dJJvTfKGOVOfWFV3WubYm7Z7Ysaq/lna7jie1AEAAHBA7bevdXwkyRuTvOmqn+7+xNgt7cjTM/uv/SeTPLy7L9vJwbv7s1X1HUneko2nXGzl2CRPS/Lvlzz8dl/fWNU/S9sdZ1VfGwEAAGCP2Q9x4tlJPpbkjd39sdGb2a2qul2Sfzdn2o9394d3s053f7Cqnp7kV2dMe1hV/dfu/sASh758m9e/YoljzHLCNq9/bkXHBwAAYI/Z81/r6O7nd/efHoQwsenxSY6ZMf7eJM9b0VrPSfL+GePHJPnBZQ64eRPNre4vcdIyx5lhu6dyfGpFxwcAAGCP2fNx4iCpqutk/tcofqW7r1zFet39xcy+ciJJHrG5r2VsFQpuvOQxtvOV27z+yRUdHwAAgD1GnFivr09yixnjlyf5nRWv+cIkV8wYv2WS+y15zI9s8drNlzzGdrY6zie729c6AAAADihxYr2+Zc74n3X3JatccPNpH6+cM23evq7pwi1eu2lVbXe/iGXcdovXlrknBgAAAPuMOLFe958z/mcTrTvvuA9Y8njv3uK1SnL7JY9z9QNU3SDJTbYYes9ujgsAAMDeJk6sSVXdIsnpc6a9ZqLlz54zfriqlvlaxpu3ef3uSxxjK2csuR4AAAAHgDixPveaM/7h3T4+dDvdfWGSf5wz7awlDvmGbV6/9xLH2Mq/WnI9AAAADgBxYn22uyrgKudOvP45c8bn7e/LuvsD2fo+EMt+PWSR91+W5PW7PC4AAAB7mDixPnefM/62idd/65zxhePEplds8dqpVbXscZIkVXXTJPfZYug13f35nRwTAACA/UGcWJ/T5oy/d+L13zdnfNmbWf7eNq8/dsnjXOX7khyzxDoAAAAcEOLE+tx2zvgFE68/7/inLHm81yV5xxavP6qqbrvMgTaf0vHkLYYuSvLyJfcFAADAPiNOrMHmkzC+Ys60j0y8jXnHP2HzqxUL6e5O8gtbDB2f5HlVVUvs7Zey9SNEn9Xdly9xHAAAAPYhcWI9brnAnI9NvIePLjBnkX0e6UXZ+l4WD0jy7EUCRVX9SJL/uMXQR5I8c8n9AAAAsA+JE+tx4znjF3f3FVNuoLs/l+TSOdPm7fOax7wyG/eY+OIWw49P8oqq2vJeFlV1y6r6nSQ/v83hn9Ddn11mPwAAAOxPx47ewFHiRnPGL17LLjbWOTRjfN4+r6W7/76qfjTJL24x/MAk766q1yd5Y5JPJTkpG08uuU+2/+fvmd39R8vuBQAAgP1JnFiPG84ZX2ecmPXVjaXjRJJ09y9t3q/iKVsMV5J/vfmziN9J8sM72QcAAAD7kzixHtebM37ZWnaRzPuaxLx9bqu7n1pVFyb5lWzcFHNZVyb56SQ/sXmzzaVsxpGtbqo5y6nLrgMAAMDqiRPrcdyc8a3u2TCFeevM2+dM3f3cqjo7yc8meUgWv6fJa5I8pbvfvIvlfzDJ03fxfgAAAAYRJ9bjqIgTSdLdFyT59qq6bTYCxf2SnJ7kqsepXp7kn5O8M8nfJHlZd79zt+sCAACwf4kT6zHvCoIr17KL+escs6qFuvvCbHzF41dWdUwAAAAOJnFiPeZdsbCuvw/z1vnCWnYxjeck+YMl33NqkpdPsBcAAACWIE6sx+fnjK/r78N154zP2+ee1d0XJblomfdU1US7AQAAYBmL3rCQ3Zl3RcKu7/WwoAMbJwAAANi/xIn1uHTO+Ilr2UVy0pzxefsEAACAlRMn1uOTc8bXFSfmrTNvnwAAALBy4sR6fGLO+Mnr2ESSG8wZn7dPAAAAWDlxYj3+ec748VV18pQbqKobZ/69LcQJAAAA1k6cWI8PLTDnZhPvYZHjL7JPAAAAWClxYg26+9LMv3riNhNvY97xL+ruz068BwAAALgWcWJ9PjBn/PYTrz/v+PP2BwAAAJMQJ9bn/Dnjd5h4/dPmjM/bHwAAAExCnFifN88ZP2Pi9c+cMz5vfwAAADAJcWJ9zp0zfveqOmaKhavq2CR3mzNNnAAAAGAIcWJ93pTk8hnjh5LcY6K175XkhBnjlyc5Z6K1AQAAYCZxYk26+/Ikfztn2gMmWv7+c8b/ZnN/AAAAsHbixHqdPWf8oROt++1zxl890boAAAAwlzixXi+dM35mVa30qR1VdTjJXeZM+8NVrgkAAADLECfWqLvfn+T1c6Y9ccXLPmnO+N919wdWvCYAAAAsTJxYv9+eM/6YqrrFKhaqqlsleeScaS9YxVoAAACwU+LE+r0oyUUzxk9I8rMrWuvnklxvxvjHNvcDAAAAw4gTa7b5VIxfnTPtkVX1kN2sU1UPS/KIOdOe2d1X7GYdAAAA2C1xYoxnJvnQnDkvrKp77eTgVXXvJL81Z9qHMj+SAAAAwOTEiQG6+7IkPzxn2olJXl1V37LMsavqwUleleTQnKk/1N2fW+bYAAAAMIVjR29gEVV1nySnLfm2eY/kPFRV37uD7fxVd793B++7mu5+aVX9XmZ/9eIGSV5eVb+f5Ke6+13bTayq05M8LcnDF1j+d7vb40MBAADYE6q7R+9hrqp6QZJHjd7Hpsd09wtWcaCqOpTkjUnuuOBb3pzkdUk+kOTSbFxdcUqSr01ytwWP8a4kZ3X3pcvt9uCpqsNJzrvqz88777wcPnx44I4AAIB9okZv4KDZF1dOHFTdfWlVPTDJ3yS59QJvOWPzZ6c+lOSBwgQAAAB7iXtODNbdH0ryDUneN/FSFyT5+s31AAAAYM8QJ/aA7r4gyVnZuJHlFF6Z5F7dPXUAAQAAgKWJE3tEd3+qux+U5NFJLlrRYS9K8qju/sbu/tSKjgkAAAAr5Z4Te0x3v7CqXpqNG4A+IcmddnCYdyb5tSQv2Hxs6VGtqs7fZuj4tW4EAACALe2Lp3UczarqtCQPSnJmksNJviobT+k4IcllSS5J8g9J3pHk3CSvWMWjTg+SOXHi1Kv+xNM6AACABXlax4q5cmKP6+73JHnP6H3sZ929ZXGoqjOyEXSSJBdccMHa9gQAAOxfd77zna/6d4z3dfflQzdzQLhygqNWVX1rkpeP3gcAALBv3bm7t7tSmyW4ISYAAAAwlDgBAAAADOVrHRy1quoGSe57xEu/kqSTPHjMjnJqrv41kwcned+gvcBBctX/rkb9b5sx/H2fnr/G13Y0/DXZz7/jftn7Xtvn6P3s9XNk95xYETfE5KjV3Z9J8sdX/XlV/czm60O+M1Z1rRv+vs/312D3quqKZNz/thnD3/fp+Wt8bUfDX5P9/Dvul73vtX2O3o9z5KOHr3UAAAAAQ7lyAthzqur0JN+U5J5JTk9y8yQnJjkmySVJPpHk3UnemuRVSV7X3VeO2S0AALBb4gSwJ1TV8Um+O8l/SnJ4xtQbbf7cPsk3J/mxJB+vqucm+Z/dfdHEWwUAgLWqquskuUOSs474uXuS47d7T3df6zsxe5k4AQxXVfdP8pxsBIeduEmSpyV5clX9eJLndPeXVrU/AABYp6o6JRtXEV8VIu6RjSuJDyxP64A9oqoOJznviJfufNBv9lMbdzj6ySQ/vuJD/+8kj9i86SkAAPvU0XKOXFVfm+SB+ZcYcePdHtOVEwAL2Lw07UVJHjHB4b8pyd9V1f26+58nOD4AAKzSj2TvPD52CE/rAEZ5bhYPE1ck+XCSC5NcuuB7Did5VVUdWn5rAADAOokTwNpV1fcn+f450y5J8gvZ+K7doe6+dXef0t0nZuPeFD+S5INzjnFmkt/Y7X4BAIBpiRPAWlXVaUmeOWfanyX5mu5+Snef091fPHKwuy/o7l/Mxh2Lfy7JrJvnPKKqvns3ewYAAKYlTgDr9qtJvmLG+POTfMsijwTt7iu6+0eTfF9mB4pfqKqTltsmAADsGVcmeVuS30ryuGxcXTzvSuR9xQ0xgbWpqgcledCMKX+e5Pt7yccIdffzq+q22f6pHzdL8l82fwAAYC/rJO9J8sYkb9r845u7+3NHTqqquwzY22TECdg7Pp7kJ67x5wfNrDhwaZJHdveXdnjsZyT5t0nO2Gb8cVX1M9198Q6PDwDA+h0N58hJ8hdJXpeNEHHO0XjOWkv+B0qAHamqe2Sj/G7nv3X3T+9yjftl44N9Oz/c3b+8mzUAAGAvqKpHJ/nt7ca7u9a3m91zzwlgXR49Y+zSJL+22wW6+y+T/J8ZUx612zUAAIDVEyeAyVXVMUm+Y8aUF3f3p1e03K/PGLtrVd15ResAAAArIk4A6/Cvktx0xviLV7jWy5JcMWP8W1e4FgAAsALiBLAO958xdmmSv17VQt39mSR/u8O9AAAAA4gTwDr8mxljf93dX1jxeq+ZMfavq+p6K14PAADYBXECmFRVVZIzZ0yZdQPLnfr7GWPHJ3HfCQAA2EOOHb0BYHGb/8X/q5OcuPnzFdn4WsQlST6d5MPd/aVhG9zaaUkOzRg/d4I1z03SSbZ7fNIZmf1YUwAA9pF9ep7MEcQJ9qSqun42/mv7PZKcvODb/nLzUZIHRlXdMck3JblvktOT3C6zr3i6vKrek+Tt2fhqwyu6+2OTb3S2u8wZf8eqF+zui6vqn5Lccpspd131mgAA6+A8ecMBOU/mCOIEw21Wzrsnuefmz1lJ7pidfe3oL1e2sUGq6uQk35vkB5J8zZJvv142/sX7rkn+Q5Kuqtcl+bUkL+3uL65wq4u63YyxLyT54ETrXpDt48QpE60JALAyzpOv7gCeJ3MEcYK1qqrjsvFf0u95xM+d45/FVNWhJP8tyeOTXH9Vh03ytZs/v1BVP5Hk+d3dKzr+ImaFgI9095UTrXthkvtsMyZOAAB7ivPk7R3g82SOcNT/g850quqYbFxidVb+5QP2rtm4ISFHqKqHJHlWkltNuMytkvxmku+pqsd299smXOua627noxOuO+vYXz3hugAAMzlPXtwBP0/mCOIEK1dVJyQ5OxuXoJ0wdjd7W1Udm+QXkzx5jcv+qyT/p6q+r7t/Zw3rfeWMsSm/5zcrTpxYVcd19+cnXB8A4GqcJy/uKDlP5ggeJcoUjkvyr+MDd6aqOinJq7LeD9yrXC/Ji6rqF9aw1o1njH1mwnUvnjN+ownXBgDYivPkBRxF58kcQZyAATar+Z8l+frBW/nPVfVLE69x8oyxSyZcd96xbzjh2gAA7MBRdp7MEcQJWLPNmx29PMnXjd7Lph+qqmdMePzrzRj77ITrzjv2rH0BALBmR+F5MkcQJ2D9fiHJ/Xfwvo8k+aUkD01yajauSLhuNr42cadsPBLpeUk+tYNjP72qvm0H71vEcTPGpnxk07xjz9oXAADrd7SdJ3MEN8SENdq82/CTlnzbBUl+NMnLuvtLW4x/cvPnXUl+r6qemOR7kvxEkpsusc5vV9VbuvvCJfc3z3VnjIkTAAAcrefJHMGVE+xFVyR5U5LfSPJjg/eyMlV1kyTPX/Jtv57kcHf/4TYfuNfS3Z/v7l9Pcockf7LEWicnedGS+9vL5j2j2jOsAYD9xnnyv3CefMCIE4z2hSRvzsZzhR+bjWc8n9jdZ3X3Y5P83sjNrdjPZLmbMD65ux+308dddvenkzw4G8+FXtTXVdV/2Ml6M3xhxtiUV2/NumIjmb0vAIDRnCdv76CcJ3MEX+tgnb6Y5B3ZqL1vSnJOkrd29xVDd7UGVXVWNi4hW9R/7e5lPiy31N2d5MlVdWiJ9X++ql7e3Zfudv1Nn09y/DZjU34GzTv2jv7PDABgAs6TF3eQzpM5gjjBVK7Mxne73nTEz1u6+/KhuxrnvyepBef+cXf/zIrX/8EkZya5+wJzb5mN7/v9jxWtfXmSE7cZm/IZ3/OOfbT+swgAjOU8+eqO5vNkjiBOMIWLk5zU3ZeN3sheUFVnJHnAgtM/keQxq95Dd19RVY9I8tbM/7pDkjypqn5pRbX+00luss3YSSs4/nbmHXsnd2sGANgN58lHcJ7MkdxzgpXr7i/5wL2apywx92nd/ckpNtHd70zyPxecfrMkj1rR0p+YMXaDFa2xlXlxYpK/zgAA23GefC1H+3kyRxAnYEJVddMk377g9A9k487LU/qpJJ9dcO4TVrTmP88Yu9mK1tjKzWeMXbLTGygBALB7zpO5JnECpvWdWfzrU8/q7iun3MxmbX7hgtPvUlV3WcGyH54xNisg7NasY39ownUBAJjPeTJXI07AtBZ93NBlWf7Zzju1zN2NV/G4pAtnjH1VVR2zgjW2ctsZYxdOtCYAAItxnszViBMwkao6Jcm9Fpz+J919yZT7uUp3vzvJuQtO/84VLPn+GWPXTXKbFayxla+ZMTZrTwAATMh5MlsRJ2A6D1pi7osn28XWfn/Bebepqjvucq23zxk/fZfHv5aqOinJLWZMmbcnAACm4zyZaxEnYDr3X3DeF5KcPeVGtvC/l5i76O+xnfckuXTG+Jm7PP52x5z1vOw3T7AmAACLcZ7MtYgTMIGquk6Sf7Pg9L/v7kXvDLwS3f2OJP+44PRFnz293Vqd2ZfH/V+7Of427j1j7Iq4cgIAYAjnyWxHnIBp3CXJDRec+xdTbmSG1y447/+eeK37VNV1V7DGkWZV7Nd19xUrXg8AgMU4T2ZL4gRMY5mvKrxxsl2sZt0bVtVtd7nWn88YO5TkPrs8/pdt3m/i62ZMec2q1gIAYGnOk9mSOAHTWOZD95zJdjHbonciTnZ/X4jXJ7loxvgq73b80CTHzxh/+QrXAgBgOc6T2ZI4AdM4Y8F5F3X3P026k+29JUkvOHfR32dL3X1lkpfMmPKdVXXybtY4wmNnjL21u89f0ToAACzPeTJbEidgGocXnPeeSXcxQ3dfmmTRD/xFf59ZXjhj7FCSJ+x2gaq6X2bfYHPWHgAAmJ7zZLYkTsCKbV4BcPKC0y+YbicrXf+U3S7U3eck+asZU55aVbfc6fGr6pgkvzxjymeSPH+nxwcAYHecJzOLOAGrt8wH1Psm28Vi1v2h+7Mzxg4leeHm46V24hmZfVndc7v74h0eGwCA3XOezLbECVi9ZT6gPjLZLhaz6DOcb1BViz7yaVvd/cokr5ox5f5JfqOqapnjVtX3JPmxGVM+luRnljkmAAAr5zyZbYkTsHq3XmLuRyfbxerXX+b3muVJST43Y/x7k/xxVd103oGq6viq+pkk/yvJrKDxI66aAAAYznky2zp29AbgAPrKJebupw/dZX6vbXX3e6rqPyX5jRnTvjnJe6vq15O8OMnbNp/4kSSpqtsl+bYkT0xy2zlL/l53v2g3ewYAYCWcJ8+w+R/dHrLEW24w53jvWnILj+zuNyz5npURJ2D1brTE3H+ebBeL+fgSc5f5vWbq7udV1T2TfN+MaSclecrmz+VVdVGSK7Px4X/igkudm+QHdrNXAABWxnnybLdIcocVHSs7ONYJK1x7aeIErN6Nl5g7+qsGlywxd5nfaxGPTXL9JI9YYO71svzlcucneeDmo6AAABjPeTLbcs8JWL1lyunof3Fe5kN3ZVdOJEl3fynJdyX5H6s87qZXJPna7h5d3AEA+BfOk9mWOAGrd2jBeZ898j4KgyxTpBf9vRbWG34syQOzmmdZX5zkyUm+ubs/s4LjAQCwOs6T2ZY4Aat33ILzrph0F4tZZg+L/l5L6+5XJ7lzNu4P8Y4dHOLjSX46ye27+1mbV2UAALC3OE9mW+45Aau36IfTFyfdxWKW2cOkH7rdfUWS5yV5XlXdOck3JrlnktOT3DwbN8E8JhuX2H0iybuTvDXJq5P8XXfvhb+eAABsz3nyDN396CSPXsWx9iNxAlZvP33ofmGJuWsrwt19XpLz1rUeAABr4TyZbflaB6zedRect98+dBf9vQAAYCvOk9mWOAGr1wvOq0l3sZhlPgMW/b0AAGArzpPZljgBq/f5Beftha9VLbOHRX8vAADYivNktiVOwOrtpw/dZS5B86ELAMBuOE9mW+IErN5++tA9Zom5PnQBANgN58lsS5yA1Vv0w+mESXexmOsvMdeHLgAAu+E8mW2JE7B6n1lw3vFVNfrOvicuMXfR3wsAALbiPJltiROwep9cYu5Jk+1i9esv83sBAMA1OU9mW+IErN4nlpi7nz50l/m9AADgmpwnsy1xAlZvmXJ6s8l2sfr1FWEAAHbDeTLbEidg9T62xNybT7aL1a9/0WS7AADgaOA8mW2JE7B6Fy4xd7986HaSD065EQAADrwLl5jrPPkoI07A6n1giblfPdkuVrv+R7v7c5PuBACAg855MtsSJ2D1PpiNgrqI20+5kRWuf+GUmwAA4KjgPJltiROwYt19eZJ/XHD610y5lwWcuuC890+6CwAADjznycwiTsA03rbgvNOqasj/DqvqZklOXnD6WyfcCgAARw/nyWxJnIBpnLvgvOsnOW3KjcxwjyXmLvr7AADALM6T2ZI4AdN48xJzl/nwW6Vl1l3m9wEAgO04T2ZL4gRM401LzL33ZLtYzbof6O5PTroTAACOFs6T2ZI4ARPo7g9m8ZvjfMOUe9lKVV03yX0WnP7aKfcCAMDRw3ky2xEnYDqvWXDenarqlpPu5NruneTQgnMX/T0AAGARzpO5FnECpnP2EnO/bapNbOMhC87rJH8+5UYAADjqOE/mWsQJmM7ZSa5YcO53TrmRI1VVJfmOBae/obs/PuV+AAA46jhP5lrECZhId38myf9ecPrXVdXtptzPEe6f5KsWnPu7U24EAICjj/NktiJOwLQW/dCqJE+eciNH+H8WnHdlkpdMuREAAI5azpO5GnECpvWnSRZ9vND3VNVXTrmZqrpLkgctOP2V3X3RlPsBAOCo5TyZqxEnYELdfUWS5y44/VCSn5xwO0nyS9moz4v4lSk3AgDA0ct5MtckTsD0npXk8gXnfn9V3WOKTVTVtyd5wILTz+1udx8GAGBKzpP5MnECJrZ5yddvLzj9mCQvrqoTV7mHqrp1kuct8ZafXeX6AABwTc6TOZI4AevxjCSfWXDu1yT5/6rquFUsXFU3TPLHSW644Ftel+Slq1gbAADmeEacJxNxAtZiswo/Y4m3PCjJS6vq+rtZt6punuTVSe624Fu+lOSJ3d27WRcAABbhPJmrlL+2TKWqnpHk6aP3sazuXvRGOEupqmOTvCHJGUu87R1J/kN3v2UH690/yf+b5BZLvO3Z3f2kZdcCAGBxzpOvznkyiSsnYG26+4tJHp7kkiXednqSc6rqt6pq7od1bbhvVf1JkrOz3AfuW5I8ZYn5AACwa86TSZJjR28Ajibd/d6q+v4kv7/E266T5DFJHlNV70ryt0neluQTST6b5KQkN81Gab5Pkq/ewdYuSfId3b3o3ZIBAGBlnCcjTsCadfeLq+rUJD+9g7ffcfNnlS5P8m3d/d4VHxcAABbmPPno5msdMEB3//fsjccQfSHJw7r7taM3AgAAzpOPXuIEDNLd/yXJU7Nx598RPpXk33b3nw5aHwAArsV58tFJnICBuvvnk3xzNj4A1+m8JGd199lrXhcAAOZynnz0ESdgsO5+RTbuNvy7a1juc0meluSe3f2+NawHAAA74jz56CJOwB7Q3R/t7u9Kct8kr55gicuT/FaSw939U919xQRrAADASjlPPnpUd4/eA3ANVXV6kh/IxqVst9vhYTrJOUleluQ3u/vjK9oeAAAM4Tz54BInYI+rqjtm47nMh7NxWdttsvHM5hOTHJ+NZzhfkuTTSS5I8s4kb0/y5939sQFbBgCAyTlPPljECQAAAGAo95wAAAAAhhInAAAAgKHECQAAAGAocQIAAAAYSpwAAAAAhhInAAAAgKHECQAAAGAocQIAAAAYSpwAAAAAhhInAAAAgKHECQAAAGAocQIAAAAYSpwAAAAAhhInAAAAgKHECQAAAGAocQIAAAAYSpwAAAAAhhInAAAAgKHECQAAAGAocQIAAAAYSpwAAAAAhhInAAAAgKHECQAAAGAocQIAAAAYSpwAAAAAhhInAAAAgKHECQAAAGAocQIAAAAYSpwAAAAAhhInAAAAgKHECQAAAGAocQIAAAAYSpwAAAAAhhInAAAAgKHECQAAAGAocQIAAAAYSpwAAAAAhhInAAAAgKHECQAAAGAocQIAAAAYSpwAAAAAhhInAAAAgKHECQAAAGAocQIAAAAYSpwAAAAAhhInAAAAgKHECQAAAGAocQIAAAAYSpwAAAAAhhInAAAAgKH+f7XFamqul6LtAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1012.5x1012.5 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.linspace(1e-2, 1e3, num=100)\n",
    "\n",
    "plt.style.use(['seaborn-paper', \"./PRLSingleCol.mplstyle\"])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.loglog(np.arange(1, len(l_n_trained) + 1), l_n_trained, label=r\"CIFAR10\")\n",
    "#ax.loglog(l_n_trained[0]*LocalLearning.stringer_spectrum(x), label=r\"$1 / n$\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(r\"$n$\")\n",
    "ax.set_ylabel(r\"$\\lambda_{n}$\")\n",
    "ax.set_title(r\"CIFAR10 Covariance Spectrum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biological Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from context import LocalLearning\n",
    "\n",
    "train_data = datasets.CIFAR10(\n",
    "    root = \"../data/CIFAR10\", train=True, download=True, transform=ToTensor()\n",
    ")\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    train_data, batch_size=128, num_workers=4, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BioLearningModel(\n",
       "  (local_learning): LocalLearningModel(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (relu): ReLU()\n",
       "  (dense): Linear(in_features=2000, out_features=10, bias=False)\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "model_path = Path(\"../data/models/L2UnitCIFAR10_LL/llmodel_L2UnitCIFAR10_5.pth\")\n",
    "ll_trained_state = torch.load(model_path)\n",
    "bio_model = LocalLearning.BioLearningModel(ll_trained_state)\n",
    "#bio_model.to(device)\n",
    "bio_model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0716, -0.0728, -0.0742,  ..., -0.0726, -0.0726, -0.0724],\n",
       "        [-0.0716, -0.0727, -0.0735,  ..., -0.0720, -0.0724, -0.0724],\n",
       "        [-0.0721, -0.0733, -0.0737,  ..., -0.0728, -0.0729, -0.0738],\n",
       "        ...,\n",
       "        [-0.0627, -0.0643, -0.0633,  ..., -0.0643, -0.0637, -0.0644],\n",
       "        [-0.0622, -0.0641, -0.0633,  ..., -0.0644, -0.0640, -0.0637],\n",
       "        [-0.0631, -0.0645, -0.0629,  ..., -0.0646, -0.0642, -0.0631]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#W_pre_training = bio_model.local_learning.W.clone()\n",
    "#plt.figure()\n",
    "#plt.hist(list(bio_model.parameters())[0].data.detach().numpy())\n",
    "#plt.show()\n",
    "\n",
    "list(bio_model.parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = lambda l: 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate(4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#optimizer = torch.optim.Adam(bio_model.parameters(), lr=0.0001)\n",
    "\n",
    "steps = 0\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for i in range(1):\n",
    "    for features, labels in dataloader_train:\n",
    "        #optimizer.zero_grad()\n",
    "        pred = bio_model(features)\n",
    "        plt.hist(np.ravel(pred.detach().numpy()), bins=np.linspace(0.0, 1.0, num=20), )\n",
    "        #print(pred)\n",
    "        #labels_one_hot = torch.zeros(pred.size())\n",
    "        #labels_one_hot.scatter_(-1, labels[..., None], 1.0)\n",
    "        #loss = torch.pow(pred - labels_one_hot, 4.0).sum()\n",
    "        #loss.backward()\n",
    "        #optimizer.step()\n",
    "        steps += 1\n",
    "        #print(list(bio_model.parameters())[1])\n",
    "    \n",
    "print(steps)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_post = list(bio_model.parameters())[1].data\n",
    "torch.equal(W_pre, W_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End-to-end backpropagation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classifier(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (hidden): Linear(in_features=3072, out_features=2000, bias=False)\n",
       "  (relu): ReLU()\n",
       "  (dense): Linear(in_features=2000, out_features=10, bias=False)\n",
       "  (relu_two): ReLU()\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.flatten.requires_grad_(False)\n",
    "        self.hidden = nn.Linear(32*32*3, 2000, bias=False)\n",
    "        self.hidden.requires_grad_(False)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense = nn.Linear(2000, 10, bias=False)\n",
    "        self.relu_two = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        hidden = self.hidden(self.flatten(x))\n",
    "        activation = torch.pow(self.relu(hidden), 4.5)\n",
    "        return self.softmax(self.dense(activation))\n",
    "\n",
    "classifier = Classifier()\n",
    "classifier.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.CIFAR10(\n",
    "    root = \"../data/CIFAR10\", train=True, download=True, transform=ToTensor()\n",
    ")\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    train_data, batch_size=128, num_workers=4, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0057, -0.0161,  0.0151,  ...,  0.0126,  0.0153, -0.0043],\n",
       "         [-0.0178, -0.0174, -0.0080,  ..., -0.0031,  0.0024, -0.0178],\n",
       "         [-0.0128,  0.0065, -0.0057,  ...,  0.0036, -0.0115, -0.0179],\n",
       "         ...,\n",
       "         [ 0.0143,  0.0145, -0.0003,  ...,  0.0177,  0.0071, -0.0105],\n",
       "         [-0.0047,  0.0028, -0.0154,  ...,  0.0027,  0.0038, -0.0042],\n",
       "         [ 0.0141,  0.0036,  0.0101,  ...,  0.0180,  0.0167,  0.0016]]),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0110,  0.0190, -0.0184,  ..., -0.0133,  0.0010, -0.0182],\n",
       "         [ 0.0149,  0.0203,  0.0185,  ..., -0.0199,  0.0076, -0.0182],\n",
       "         [-0.0079, -0.0096, -0.0169,  ...,  0.0033,  0.0203,  0.0060],\n",
       "         ...,\n",
       "         [ 0.0180,  0.0166,  0.0055,  ..., -0.0124, -0.0059, -0.0129],\n",
       "         [ 0.0084, -0.0085, -0.0119,  ...,  0.0105,  0.0023, -0.0041],\n",
       "         [ 0.0135,  0.0062,  0.0137,  ...,  0.0090, -0.0057, -0.0153]],\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(classifier.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim \n",
    "\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\n",
    "\n",
    "for features, labels in dataloader_train:\n",
    "    optimizer.zero_grad()\n",
    "    pred = classifier(features)\n",
    "    labels_one_hot = torch.zeros(pred.size())\n",
    "    labels_one_hot.scatter_(-1, labels[..., None], 1.0)\n",
    "    loss = torch.pow(pred - labels_one_hot, 6.0).sum()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.0057, -0.0161,  0.0151,  ...,  0.0126,  0.0153, -0.0043],\n",
       "         [-0.0178, -0.0174, -0.0080,  ..., -0.0031,  0.0024, -0.0178],\n",
       "         [-0.0128,  0.0065, -0.0057,  ...,  0.0036, -0.0115, -0.0179],\n",
       "         ...,\n",
       "         [ 0.0143,  0.0145, -0.0003,  ...,  0.0177,  0.0071, -0.0105],\n",
       "         [-0.0047,  0.0028, -0.0154,  ...,  0.0027,  0.0038, -0.0042],\n",
       "         [ 0.0141,  0.0036,  0.0101,  ...,  0.0180,  0.0167,  0.0016]]),\n",
       " Parameter containing:\n",
       " tensor([[-0.1682, -0.0894, -0.1055,  ..., -0.0870, -0.1443, -0.0445],\n",
       "         [ 0.0597, -0.0100,  0.0443,  ...,  0.1123,  0.0917,  0.0718],\n",
       "         [-0.0711,  0.0364, -0.1270,  ..., -0.1561, -0.1763, -0.1152],\n",
       "         ...,\n",
       "         [ 0.0317,  0.0624,  0.0866,  ..., -0.1071, -0.0031, -0.0434],\n",
       "         [-0.1795, -0.1541, -0.1571,  ...,  0.0341, -0.0771, -0.0836],\n",
       "         [ 0.1219, -0.1365,  0.1390,  ..., -0.0028,  0.1732,  0.0729]],\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(classifier.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_state_dict': OrderedDict([('W',\n",
       "               tensor([[-0.0741, -0.0739, -0.0741,  ..., -0.0742, -0.0741, -0.0739],\n",
       "                       [-0.0737, -0.0737, -0.0736,  ..., -0.0736, -0.0738, -0.0737],\n",
       "                       [-0.0741, -0.0743, -0.0742,  ..., -0.0740, -0.0742, -0.0744],\n",
       "                       ...,\n",
       "                       [-0.0646, -0.0644, -0.0645,  ..., -0.0647, -0.0645, -0.0644],\n",
       "                       [-0.0647, -0.0643, -0.0648,  ..., -0.0645, -0.0644, -0.0647],\n",
       "                       [-0.0651, -0.0649, -0.0648,  ..., -0.0647, -0.0647, -0.0649]],\n",
       "                      device='cuda:0'))]),\n",
       " 'model_parameters': {'in_size': 3072,\n",
       "  'hidden_size': 2000,\n",
       "  'n': 4.5,\n",
       "  'p': 3,\n",
       "  'tau_l': 5000.0,\n",
       "  'k': 7,\n",
       "  'Delta': 0.4,\n",
       "  'R': 1.0},\n",
       " 'device_type': 'cuda'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
